{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_finetuned = \"JackismyShephard/speecht5_tts-finetuned-nst-da\"\n",
    "\n",
    "revision = \"5af228df418092b681cf31c31e413bdd2b5f9c8c\"\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-to-speech\",\n",
    "    model=checkpoint_finetuned,\n",
    "    use_fast=True,\n",
    "    device=device,\n",
    "    revision=revision,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = \"../../embeddings/nst-da-metricgan-plus/\"\n",
    "\n",
    "speaker_embeddings = {\n",
    "    \"F23\": embeddings_dir + \"female_23_vestjylland.npy\",\n",
    "    \"F24\": embeddings_dir + \"female_24_storkoebenhavn.npy\",\n",
    "    \"F49\": embeddings_dir + \"female_49_nordjylland.npy\",\n",
    "    \"M51\": embeddings_dir + \"male_51_vest_sydsjaelland.npy\",\n",
    "    \"M18\": embeddings_dir + \"male_18_vest_sydsjaelland.npy\",\n",
    "    \"M31\": embeddings_dir + \"male_31_fyn.npy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dtype = np.int16\n",
    "max_range = np.iinfo(target_dtype).max\n",
    "\n",
    "\n",
    "def replace_danish_letters(text):\n",
    "    for src, dst in replacements:\n",
    "        text = text.replace(src, dst)\n",
    "    return text\n",
    "\n",
    "\n",
    "replacements = [\n",
    "    (\"&\", \"og\"),\n",
    "    (\"\\r\", \" \"),\n",
    "    (\"¬¥\", \"\"),\n",
    "    (\"\\\\\", \"\"),\n",
    "    (\"¬®\", \" \"),\n",
    "    (\"√Ö\", \"AA\"),\n",
    "    (\"√Ü\", \"AE\"),\n",
    "    (\"√â\", \"E\"),\n",
    "    (\"√ñ\", \"OE\"),\n",
    "    (\"√ò\", \"OE\"),\n",
    "    (\"√°\", \"a\"),\n",
    "    (\"√§\", \"ae\"),\n",
    "    (\"√•\", \"aa\"),\n",
    "    (\"√®\", \"e\"),\n",
    "    (\"√Æ\", \"i\"),\n",
    "    (\"√¥\", \"oe\"),\n",
    "    (\"√∂\", \"oe\"),\n",
    "    (\"√∏\", \"oe\"),\n",
    "    (\"√º\", \"y\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
    "\n",
    "speaker_model = EncoderClassifier.from_hparams(\n",
    "    source=spk_model_name,\n",
    "    run_opts={\"device\": device},\n",
    "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
    ")\n",
    "\n",
    "\n",
    "def create_speaker_embedding(waveform):\n",
    "    with torch.no_grad():\n",
    "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
    "    return speaker_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import SpectralMaskEnhancement\n",
    "\n",
    "metricgan_model_name = \"speechbrain/metricgan-plus-voicebank\"\n",
    "\n",
    "\n",
    "enhance_model = SpectralMaskEnhancement.from_hparams(\n",
    "    source=metricgan_model_name,\n",
    "    savedir=os.path.join(\"/tmp\", metricgan_model_name),\n",
    "    run_opts={\"device\": device},\n",
    ")\n",
    "\n",
    "\n",
    "def enhance_audio(waveform):\n",
    "    tensor = torch.tensor(waveform).reshape(1, -1).float()\n",
    "    enhanced = enhance_model.enhance_batch(tensor, lengths=torch.tensor([1.0]))\n",
    "    enhanced = enhanced.squeeze().cpu().numpy()\n",
    "    return enhanced\n",
    "\n",
    "\n",
    "def enhance_audio_file(file):\n",
    "    enhanced = enhance_model.enhance_file(file)\n",
    "    enhanced = enhanced.squeeze().cpu().numpy()\n",
    "    return enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "\n",
    "def predict(text, speaker, audio=None):\n",
    "    if len(text.strip()) == 0:\n",
    "        return (16000, np.zeros(0))\n",
    "\n",
    "    text = replace_danish_letters(text)\n",
    "    if audio:\n",
    "        audio_float = (audio[1] / max_range).astype(np.float32)\n",
    "        resampled_audio = librosa.resample(\n",
    "            audio_float, orig_sr=audio[0], target_sr=16000\n",
    "        )\n",
    "        # speaker_embedding = create_speaker_embedding(enhance_audio_file(audio))\n",
    "        speaker_embedding = create_speaker_embedding(enhance_audio(resampled_audio))\n",
    "    else:\n",
    "        speaker_id = speaker[:3]\n",
    "\n",
    "        speaker_embedding_path = speaker_embeddings[speaker_id]\n",
    "\n",
    "        speaker_embedding = np.load(speaker_embedding_path)\n",
    "\n",
    "    speaker_embedding = torch.tensor(speaker_embedding).unsqueeze(0)\n",
    "\n",
    "    forward_params = {\"speaker_embeddings\": speaker_embedding}\n",
    "    speech = pipe(text, forward_params=forward_params)\n",
    "\n",
    "    sr, audio = speech[\"sampling_rate\"], speech[\"audio\"]\n",
    "\n",
    "    audio = (audio * max_range).astype(np.int16)\n",
    "\n",
    "    return sr, audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Danish Speech Synthesis\"\n",
    "\n",
    "description = (\n",
    "    \"Synthesize long-form danish speech from text with the click of a button! Demo uses the\"\n",
    "    f\" checkpoint [{checkpoint_finetuned}](https://huggingface.co/{checkpoint_finetuned}) and ü§ó Transformers to synthesize speech\"\n",
    "    \".\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    [\n",
    "        \"I sin oprindelige f√∏r-kristne form blev alferne sandsynligvis opfattet som en personificering af det land og den natur, der omgav menneskene, dvs. den opdyrkede jord, g√•rden og de naturressourcer, som h√∏rte dertil. De var guddommelige eller delvis guddommelige v√¶sener, der besad magiske kr√¶fter, som de brugte b√•de til fordel og ulempe for menneskene.\",\n",
    "        \"F23 (Female, 23, Vestjylland)\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Input Text\"),\n",
    "        gr.Radio(\n",
    "            label=\"Preset speaker\",\n",
    "            choices=[\n",
    "                \"F23 (Female, 23, Vestjylland)\",\n",
    "                \"F24 (Female, 24, Stork√∏benhavn)\",\n",
    "                \"F49 (Female, 49 Nordjylland)\",\n",
    "                \"M51 (Male. 51, Vest-sydsj√¶lland)\",\n",
    "                \"M18 (Male, 18, Vest-sydj√¶lland)\",\n",
    "                \"M31 (Male, 31, Fyn)\",\n",
    "            ],\n",
    "            value=\"F23 (Female, 23, Vestjylland)\",\n",
    "        ),\n",
    "        # gr.Audio(label=\"Custom speaker\", type=\"filepath\"),\n",
    "        gr.Audio(label=\"Custom speaker\", type=\"numpy\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Audio(label=\"Generated Speech\", type=\"numpy\"),\n",
    "    ],\n",
    "    title=title,\n",
    "    description=description,\n",
    "    examples=examples,\n",
    "    cache_examples=True,\n",
    "    allow_flagging=\"never\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
