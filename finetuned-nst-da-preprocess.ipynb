{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# hf_home_dir = \"./hf_cache\"\n",
    "# os.environ[\"HF_HOME\"] = hf_home_dir  # TODO outcomment this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"alexandrainst/nst-da\")\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_train_samples = int(10000 * 0.9)\n",
    "# num_test_samples = int(10000 * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# random.seed(10)\n",
    "# train_rands = random.sample(range(len(dataset['train'])), num_train_samples)\n",
    "# dataset['train'] = dataset['train'].select(train_rands)\n",
    "\n",
    "# test_rands = random.sample(range(len(dataset['test'])), num_test_samples)\n",
    "# dataset['test'] = dataset['test'].select(test_rands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor\n",
    "\n",
    "checkpoint = \"microsoft/speecht5_tts\"\n",
    "processor = SpeechT5Processor.from_pretrained(checkpoint)\n",
    "tokenizer = processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.filter(\n",
    "    lambda x: not (set(\"0123456789\") & set(x)), input_columns=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "    all_text = \" \".join(batch[\"text\"])\n",
    "    vocab = list(set(all_text))\n",
    "    return {\"vocab\": [vocab]}\n",
    "\n",
    "\n",
    "vocabs = dataset.map(\n",
    "    extract_all_chars,\n",
    "    batched=True,\n",
    "    batch_size=-1,\n",
    "    keep_in_memory=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "dataset_vocab = set(vocabs[\"train\"][\"vocab\"][0] + vocabs[\"test\"][\"vocab\"][0])\n",
    "tokenizer_vocab = {k for k, _ in tokenizer.get_vocab().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vocab = dataset_vocab - tokenizer_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = [\n",
    "    (\"&\", \"og\"),\n",
    "    (\"\\r\", \" \"),\n",
    "    (\"´\", \"\"),\n",
    "    (\"\\\\\", \"\"),\n",
    "    (\"¨\", \" \"),\n",
    "    (\"Å\", \"AA\"),\n",
    "    (\"Æ\", \"AE\"),\n",
    "    (\"É\", \"E\"),\n",
    "    (\"Ö\", \"OE\"),\n",
    "    (\"Ø\", \"OE\"),\n",
    "    (\"á\", \"a\"),\n",
    "    (\"ä\", \"ae\"),\n",
    "    (\"å\", \"aa\"),\n",
    "    (\"è\", \"e\"),\n",
    "    (\"î\", \"i\"),\n",
    "    (\"ô\", \"oe\"),\n",
    "    (\"ö\", \"oe\"),\n",
    "    (\"ø\", \"oe\"),\n",
    "    (\"ü\", \"y\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_text(inputs):\n",
    "    for src, dst in replacements:\n",
    "        inputs[\"text\"] = inputs[\"text\"].replace(src, dst)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "dataset = dataset.map(cleanup_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "speaker_counts = defaultdict(int)\n",
    "\n",
    "for speaker_id in dataset[\"train\"][\"speaker_id\"]:\n",
    "    speaker_counts[speaker_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(speaker_counts.values(), bins=20)\n",
    "plt.ylabel(\"Speakers\")\n",
    "plt.xlabel(\"Examples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_speaker(speaker_id):\n",
    "    return 280 <= speaker_counts[speaker_id] <= 327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].filter(\n",
    "    select_speaker,\n",
    "    input_columns=[\"speaker_id\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(dataset[\"train\"][\"speaker_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id_examples = [\n",
    "    (k, v) for (k, v) in list(speaker_counts.items()) if 280 <= v <= 327\n",
    "]\n",
    "speaker_id_examples_sorted = sorted(\n",
    "    speaker_id_examples, key=lambda x: x[1], reverse=True\n",
    ")\n",
    "speaker_id_examples_sorted[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "spk_model_name = \"speechbrain/spkrec-xvect-voxceleb\"\n",
    "\n",
    "speaker_model = EncoderClassifier.from_hparams(\n",
    "    source=spk_model_name,\n",
    "    run_opts={\"device\": device},\n",
    "    savedir=os.path.join(\"/tmp\", spk_model_name),\n",
    ")\n",
    "\n",
    "\n",
    "def create_speaker_embedding(waveform):\n",
    "    with torch.no_grad():\n",
    "        speaker_embeddings = speaker_model.encode_batch(torch.tensor(waveform))\n",
    "        speaker_embeddings = torch.nn.functional.normalize(speaker_embeddings, dim=2)\n",
    "        speaker_embeddings = speaker_embeddings.squeeze().cpu().numpy()\n",
    "    return speaker_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import SpectralMaskEnhancement\n",
    "\n",
    "metricgan_model_name = \"speechbrain/metricgan-plus-voicebank\"\n",
    "\n",
    "\n",
    "enhance_model = SpectralMaskEnhancement.from_hparams(\n",
    "    source=metricgan_model_name,\n",
    "    savedir=os.path.join(\"/tmp\", metricgan_model_name),\n",
    "    run_opts={\"device\": device},\n",
    ")\n",
    "\n",
    "\n",
    "def enhance_audio(waveform):\n",
    "    tensor = torch.tensor(waveform).reshape(1, -1).float()\n",
    "    enhanced = enhance_model.enhance_batch(tensor, lengths=torch.tensor([1.0]))\n",
    "    enhanced = enhanced.squeeze().cpu().numpy()\n",
    "    return enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resemble_enhance.enhancer.inference import enhance\n",
    "from IPython.utils import io\n",
    "\n",
    "\n",
    "def mega_enhance_audio(\n",
    "    waveform, sr, device=\"cuda\", nfe=64, solver=\"midpoint\", lambd=0.9, tau=0.95\n",
    "):\n",
    "    tensor = torch.tensor(waveform).float()\n",
    "    with io.capture_output() as _:\n",
    "        enhanced, new_sr = enhance(\n",
    "            tensor, sr, device, nfe=nfe, solver=solver, lambd=lambd, tau=tau\n",
    "        )\n",
    "    enhanced_cpu = enhanced.cpu().numpy()\n",
    "    return enhanced_cpu, new_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"JackismyShephard/nst-da-norm\"\n",
    "\n",
    "dataset[\"train\"].push_to_hub(\n",
    "    dataset_id, split=\"train\", commit_message=\"add train split\"\n",
    ")\n",
    "\n",
    "dataset[\"test\"].push_to_hub(dataset_id, split=\"test\", commit_message=\"add test split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import DatasetCard, DatasetCardData\n",
    "\n",
    "# Using the Default Template\n",
    "card_data = DatasetCardData(\n",
    "    size_categories=\"100K<n<1M\",\n",
    "    license=\"cc0-1.0\",\n",
    "    task_categories=[\"automatic-speech-recognition\", \"text-to-speech\"],\n",
    "    language=\"da\",\n",
    "    pretty_name=\"NST-da Normalized\",\n",
    "    annotations_creators=[\"machine-generated\", \"expert-generated\"],\n",
    "    language_creators=[\"expert-generated\"],\n",
    "    multilinguality=\"monolingual\",\n",
    "    source_datasets=\"extended\",\n",
    ")\n",
    "card = DatasetCard.from_template(\n",
    "    card_data,\n",
    ")\n",
    "card.push_to_hub(dataset_id, commit_message=\"update dataset card\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_23_vestjylland = dataset[\"train\"].filter(\n",
    "    lambda x: x == 202, input_columns=[\"speaker_id\"]\n",
    ")[2]\n",
    "female_24_storkoebenhavn = dataset[\"train\"].filter(\n",
    "    lambda x: x == 404, input_columns=[\"speaker_id\"]\n",
    ")[55]\n",
    "female_49_nordjylland = dataset[\"train\"].filter(\n",
    "    lambda x: x == 419, input_columns=[\"speaker_id\"]\n",
    ")[1]\n",
    "male_51_vest_sydsjaelland = dataset[\"train\"].filter(\n",
    "    lambda x: x == 475, input_columns=[\"speaker_id\"]\n",
    ")[1]\n",
    "male_18_vest_sydsjaelland = dataset[\"train\"].filter(\n",
    "    lambda x: x == 83, input_columns=[\"speaker_id\"]\n",
    ")[17]\n",
    "male_31_fyn = dataset[\"train\"].filter(lambda x: x == 496, input_columns=[\"speaker_id\"])[\n",
    "    37\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_22_oestjylland = dataset[\"train\"].filter(\n",
    "    lambda x: x == 301, input_columns=[\"speaker_id\"]\n",
    ")[0]\n",
    "female_24_storkoebenhavn_2 = dataset[\"train\"].filter(\n",
    "    lambda x: x == 404, input_columns=[\"speaker_id\"]\n",
    ")[0]\n",
    "female_44_nordjylland = dataset[\"train\"].filter(\n",
    "    lambda x: x == 517, input_columns=[\"speaker_id\"]\n",
    ")[0]\n",
    "\n",
    "male_18_vest_syd_sjaelland = dataset[\"train\"].filter(\n",
    "    lambda x: x == 83, input_columns=[\"speaker_id\"]\n",
    ")[2]\n",
    "male_31_fyn_2 = dataset[\"train\"].filter(\n",
    "    lambda x: x == 496, input_columns=[\"speaker_id\"]\n",
    ")[8]\n",
    "male_55_storkoebenhavn = dataset[\"train\"].filter(\n",
    "    lambda x: x == 43, input_columns=[\"speaker_id\"]\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_list = [\n",
    "    (female_23_vestjylland, \"female_23_vestjylland.npy\"),\n",
    "    (female_24_storkoebenhavn, \"female_24_storkoebenhavn.npy\"),\n",
    "    (female_49_nordjylland, \"female_49_nordjylland.npy\"),\n",
    "    (male_51_vest_sydsjaelland, \"male_51_vest_sydsjaelland.npy\"),\n",
    "    (male_18_vest_sydsjaelland, \"male_18_vest_sydsjaelland.npy\"),\n",
    "    (male_31_fyn, \"male_31_fyn.npy\"),\n",
    "]\n",
    "\n",
    "speaker_embeddings_list = [\n",
    "    (create_speaker_embedding(enhance_audio(speaker[\"audio\"][\"array\"])), file_name)\n",
    "    for (speaker, file_name) in speaker_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_list_2 = [\n",
    "    (female_22_oestjylland, \"female_22_oestjylland.npy\"),\n",
    "    (female_24_storkoebenhavn_2, \"female_24_storkoebenhavn.npy\"),\n",
    "    (female_44_nordjylland, \"female_44_nordjylland.npy\"),\n",
    "    (male_18_vest_syd_sjaelland, \"male_18_vest_syd_sjaelland.npy\"),\n",
    "    (male_31_fyn_2, \"male_31_fyn.npy\"),\n",
    "    (male_55_storkoebenhavn, \"male_55_storkoebenhavn.npy\"),\n",
    "]\n",
    "\n",
    "speaker_embeddings_list_2 = [\n",
    "    (\n",
    "        create_speaker_embedding(\n",
    "            mega_enhance_audio(\n",
    "                speaker[\"audio\"][\"array\"], speaker[\"audio\"][\"sampling_rate\"]\n",
    "            )[0]\n",
    "        ),\n",
    "        file_name,\n",
    "    )\n",
    "    for (speaker, file_name) in speaker_list_2\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_metricgan_plus = \"./embeddings/nst-da-metricgan-plus/\"\n",
    "root_resemble_enhance = \"./embeddings/nst-da-resemble-enhance/\"\n",
    "Path(root_metricgan_plus).mkdir(parents=True, exist_ok=True)\n",
    "Path(root_resemble_enhance).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for embedding, file_name in speaker_embeddings_list:\n",
    "    np.save(root_metricgan_plus + file_name, embedding)\n",
    "\n",
    "for embedding, file_name in speaker_embeddings_list_2:\n",
    "    np.save(root_resemble_enhance + file_name, embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
