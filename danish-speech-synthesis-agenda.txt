optimize inference
	- use torch.compile for inference
	- use int8 (use_fp8?) mixed precision training 
	- remember to load vocoder to gpu
	- use optimum/ONNX runtime (ORT)

try other models
	facebook/mms
	metavoiceio/metavoice-1B-v0.1
	coqui/XTTS-v2

compile nst-da + folketinget balanced dataset
	-flere mænd
	- længere audio klip
	- bedre optagelseskvalitet

